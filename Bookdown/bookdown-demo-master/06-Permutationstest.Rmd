```{r, include = FALSE}
library(mosaic)
library(SimDesign)
```
# Resampling-metoder

FIXME: Bland med kapitel 3 (overvej)

## Permutationstest

For at en t-test overholder den nominelle risiko for fejl, er der visse antagelser, der skal være opfyldt, heriblandt, at stikprøven skal være normalfordelt og opnået ved tilfældig stikprøveudtagning. Er disse antagelser ikke opfyldt, giver testen ikke et retvisende resultat, hvilket i dette afsnit vil eftervises ved hjælp af en permutationstest i R. Først gives en kort introduktion til permutationer, herefter en forklaring af, hvad en permutationstest er, og til sidst modbevises de resultater, opnåes, hvis en t-test udføres på data, der ikke overholder kravene.

### Permutationer

I dette afsnit defineres permutationer, og der gives et kort eksempel på en permutation af en ordnet liste af tre elementer. Afsnittet er skrevet på baggrund af [@Permutationer].

Givet en ordnet liste, $X = [x_1, x_2, \ldots, x_n ]$, er en permutation, $\pi$, en omarrangering af listens elementer, $X_\pi = [x_{\pi(1)}, x_{\pi(2)}, \ldots, x_{\pi(n)}]$. Antallet af mulige permutationer af en ordnet liste, $X$, af længde $n$, er givet ved $n!$.

Som eksempel, er en mulig permutation, $\pi_1$, af $A = [1, 2, 3]$ givet ved $A_{\pi_1} = [2, 1, 3]$, og der er i alt $|A| = 3! = 1 \cdot 2 \cdot 3 = 6$ mulige permutationer af listen. 

### Test ved hjælp af permutationer

I dette afsnit gives en forklaring af, hvad en permutationstest er. Afsnittet er skrevet på baggrund af [@Permutationstest]

Antag, at en tilfældig stikprøveudtagning af en population kan udtrykkes ved $X = [x_1, x_2, \ldots, x_n]$. Der opstilles en nulhypotese $H_0$ og en alternativ hypotese, $H_1$, der er relevante at undersøge. Der kan så vælges en teststørrelse at undersøge for at teste validiteten af $H_0$. værdien af denne teststørrelse er givet ved $S_{obs}$ for stikprøven.

En permutationstest går ud på at forsøge at måle evidens imod $H_0$, som i en almindelig t-test. Dette gøres ved at beregne teststørrelsen for samtlige permutationer af $X$. Denne mængde af permutationer er givet ved $\Pi_X = \{X_{\pi(1)}, X_{\pi(2)}, \ldots X_{\pi(m)} \}$, hvor $m$ er antallet af mulige permutationer af $X$. Teststørrelsen for den $i$'te permutation benævnes $S_{\pi_i}$.

Ved nu at undersøge, hvor stor en andel af $S_{\pi_i}$, der har en mere ekstrem værdi end $S_{obs}$, findes en _p_-værdi for testen. Dette kan skrives som $p = \frac{\# S_{\pi_i}~ \text{mere ekstrem end}~ S_{obs}}{m}$.

Denne form for test har den fordel, at den antager meget lidt omkring stikprøven. I særdeleshed antager den hverken tilfældig stikprøveudtagning, eller at populationen, fra hvilken stikprøven stammer, er normalfordelt. Der er dog visse ulemper ved en permutationstest. For det første, skal det antages, at den del af data, der permuteres, er ombyttelig. For det andet er det ikke alle teststørrelser, der kan testes ved hjælp af en permutationstest - for eksempel vil middelværdien af samtlige permutationer være lig hinanden. For det tredje bliver antallet af mulige permutationer hurtigt meget stor, når størrelsen af stikprøven stiger - hvis der for eksempel er $n = 10$ datapunkter i stikprøven, vil der være $10! = 3,628,800$ mulige permutationer af stikprøven.

Netop på grund af ombytteligheden af stikprøven, fungerer permutationstests. Hvis stikprøven er ombyttelig, vil hver eneste permutation af stikprøven, inklusiv stikprøven selv, være lige sandsynlige. Dette medfører, at hvis $H_0$ er sand, vil enhver difference imellem $S_{obs}$ og $S_{\pi_i}$ være lille og tilfældig. Hvis værdien for $S_{obs}$ på den måde konkluderes at være væsentlig anderledes, tyder det på, at $H_0$ skal forkastes.

Det store antal af permutationer afhjælpes ved kun at beregne $S_{\pi_i}$ for et passende antal, tilfældigt udvalgte, permutationer af stikprøven, og et acceptabelt resultat vil stadig blive opnået.

#### Eksempel

FIXME: Lav et eksempel, der tager udgangspunkt i realistisk data. Overvej, om eksemplet skal slettes.

Antag, at det ønskes undersøgt, om middelværdien af to populationer, $T_1$ og $T_2$, er signifikant anderledes. Til dette er nedenstående stikprøver tilgængelige.

```{r}
t_1 <- c(70, 75)
t_2 <- c(76, 72)
mean_difference <- abs(mean(t_1) - mean(t_2))
mean_difference
```

Der opstilles en nulhypotese, at middelværdien af $t_1$, $\bar{t_1}$ er lig middelværdien af $t_2$, $\bar{t_2}$ - $H_0: \bar t_1 - \bar t_2 = 0$, med den alternative hypotese $H_1: \bar t_1 - \bar t_2 \neq 0$. Teststørrelsen vil i dette tilfælde være forskellen mellem $t_1$ og $t_2$, $S_{obs} = |t_1 - t_2|$. Hvorvidt denne forskel er signifikant kan nu undersøges ved at beregne forskellen i middelværdi for samtlige permutationer af stikprøven.

I nedenstående kode oprettes en matrix, hvori hver søjle repræsenterer en permutation af stikprøven, hvor de to første rækker er værdier for $t_1$ og de to sidste rækker er værdier for $t_2$.
```{r}
set.seed(1)
t <- c(70, 75, 76, 72)
perm_samples <- matrix(0, nrow = 4, ncol = 6)
for(i in 1:6){
  perm_samples[,i] <- sample(t, size = 4, replace = FALSE)
}
perm_samples
```

I nedenstående kode beregnes den absolutte forskel i middelværdierne af hver af de permuterede datasæt, og gemmer den forskel i en liste.
```{r}
mean_list <- c()
for(i in 1: 6){
  mean_list[i] <- abs(mean(perm_samples[1:2, i]) - mean(perm_samples[3:4, i]))
}
mean_list
```

Nu kan p-værdien beregnes, hvilket gøres i nedenstående kodestykke.
```{r}
extreme_values <- 0
for(i in 1:length(mean_list)){
  if(mean_list[i] >= mean_difference){
    extreme_values <- extreme_values + 1
  }
}
p_value <- extreme_values/length(mean_list)
p_value
```

Der er altså ikke belæg for at forkaste nulhypotesen, hvorfor konklusionen må være, at middelværdien for $T_1$ er lig middelværdien for $T_2$.

### T-test for ikke-normalfordelt stikprøve

FIXME: Skriv afsnittet om på baggrund af Mikkels kommentarer fra vejledermøde 14/4-2020.

Foretages en t-test på en ikke-normaltfordelt stikprøve, giver det forkerte resultater. Eksempelvis kunne dette være, at der er en hypotese om, at middelværdidifferencen for tiden brugt på to forskellige eksaminer er $0$. Her opstilles en nulhypotese, $H_0 : \mu_1 - \mu_2 = 0$ og en alternativ hypotese, $H_a : \mu_1 - \mu_2 \neq 0$. Til denne undersøgelse er der to stikprøver på størrelsen, $n=10,000$.

```{r}
n_eksamen = 100
set.seed(1)
Eksamen_1 <- rValeMaurelli(10000, mean=10, sigma=5, skew=1, kurt=3)
Eksamen_2 <- rValeMaurelli(10000, mean=1, sigma=10, skew=-1, kurt=2)
```

```{r echo=FALSE}
hist(Eksamen_1)
hist(Eksamen_2)
```

Den indbyggede funktion til t-test, `t.test`, benyttes, hvilket giver følgende resultat.
```{r}
observeret_forskel <- abs(mean(Eksamen_1) - mean(Eksamen_2))
eksamen_t_obs <- 234.33
eksamen_p <- 2.2e-16

t.test(Eksamen_1, Eksamen_2, alternative = "two.sided", mu = 0, conf.level = 0.95)
```

Dette giver, at stikprøvernes middelværdier har en forskel på ```r observeret_forskel```, men at den tilhørende t-værdi er ```r eksamen_t_obs``` med en p-værdi på ```r eksamen_p```. altså forkastes nulhypotesen, og resultatet er, at der er forskel i tiden brugt på de to eksaminer, og at den sande difference med $95\%$ sikkerhed ligger i intervallet $[8.91; 9.07]$. Samme undersøgelse udføres nu igen, men denne gang på baggrund af en permutationstest.

```{r}
perm_eksamen_1 <- matrix(0, nrow = 100, ncol = 100)
for(i in 1:100){
  perm_eksamen_1[,i] <- sample(x = Eksamen_1, size = 100, 
                               replace = FALSE, prob = NULL)
}

perm_eksamen_2 <- matrix(0, nrow = 100, ncol = 100)
for(i in 1:100){
  perm_eksamen_2[,i] <- sample(x = Eksamen_2, size = 100,
                               replace = FALSE, prob = NULL)
}

means_perm_eksamen <- list()
for(i in 1:100){
  means_perm_eksamen[i] <- abs(mean(perm_eksamen_1[,i]) - mean(perm_eksamen_2[,i]))
}
```

Andelen af differencer, der ligger i konfidensintervallet kan nu beregnes.

```{r}

forekomst_konf <- 0
for(i in 1:100){
  if( (means_perm_eksamen[i] >= 8.91)&(means_perm_eksamen[i] <= 9.07) ){
    forekomst_konf <- forekomst_konf +1}
}

andel_perm <- forekomst_konf/100

p_numerator <- 0
for(i in 1:100){
  if (means_perm_eksamen[i] >= observeret_forskel){
    p_numerator <- p_numerator + 1
  }
}

p_vaerdi <- p_numerator / 100

```

Dette giver en andel af middelværdidifferencer på ```r andel_perm```, som betyder, at i $11\%$ af tilfældene lå middelværdidifferencen i konfidensintervallet, hvilket ikke stemmer overens med t-testens konfidens på $95\%$. Resultaterne for en t-test udført på stikprøver, der ikke overholder kravene, giver altså en forkert konfidens. Desuden fåes en p-værdi på ```r p_vaerdi```, hvorfor nulhypotesen ikke kan forkastes. Dette strider også mod resultatet fra t-testen. 








<!-- Fordelingen forekommer at være skæv, så det er ikke den bedste idè at foretage en t-test, men det forøges alligevel. -->

<!-- I R kan man foretage en t-test ved nedenstående kode. -->
<!-- ```{r} -->
<!-- set.seed(1) -->

<!-- forventet_forskel <- 0 # Forventet median -->
<!-- observeret_forskel <- abs(mean(Eksamen_1) - mean(Eksamen_2)) # Observeret median -->

<!-- eksamen1_sd <- sd(Eksamen_1) # Standardafvigelsen for eksamen 1 -->
<!-- eksamen2_sd <- sd(Eksamen_2) # Standardafvigelsen for eksamen 2 -->

<!-- eksamen_ese <- sqrt((eksamen1_sd^2/n_eksamen) + (eksamen2_sd^2/n_eksamen)) # Estimeret standardfejl -->

<!-- eksamen_t_obs <- abs((observeret_forskel - forventet_forskel)/eksamen_ese) # Observeret teststørrelse -->
<!-- eksamen_p = 2 * (1 - pdist("t", q = eksamen_t_obs, df = n_eksamen-1, plot = FALSE)) # P-værdi -->
<!-- eksamen_p -->
<!-- ``` -->





