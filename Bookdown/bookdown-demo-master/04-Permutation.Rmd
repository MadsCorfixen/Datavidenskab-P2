---
output:
  pdf_document: default
  html_document: default
---
```{r, include = FALSE}
library(mosaic)
library(SimDesign)
library(gtools)
library(cowplot)
```
# Permutationer

I afsnit \@ref(t-test) blev der redegjort for visse antagelser, der skal være opfyldt, for at en t-test giver retvisende resultater. Ligeledes blev der i afsnit \@ref(t-test2) vist hvorledes en t-tests resultater kan være misvisende, hvis stikprøverne ikke er normalfordelte. I dette kapitel vil der redegøres for en løsning til dette problem. Hvis antagelserne ikke er opfyldte, og en t-test ikke kan anvendes, kan der udnyttes permutationer.

I dette afsnit defineres permutationer, og der gives et kort eksempel på en permutation af en ordnet liste af tre elementer. Afsnittet er skrevet på baggrund af [@Permutationer]. Senere vil der gives en forklaring af, hvad en permutationstest er, og et eksempel på henholdsvis en parret og en uparret permutationstest vil gives.

Givet en ordnet liste, $X = [x_1, x_2, \ldots, x_n ]$, er en permutation, $\pi$, en omarrangering af listens elementer, $X_\pi = [x_{\pi(1)}, x_{\pi(2)}, \ldots, x_{\pi(n)}]$. Antallet af mulige permutationer af en ordnet liste, $X$, af længde $n$, er givet ved $n!$.

Som eksempel, er en mulig permutation, $\pi_1$, af $A = [1, 2, 3]$ givet ved $A_{\pi_1} = [2, 1, 3]$, og der er i alt $|A| = 3! = 1 \cdot 2 \cdot 3 = 6$ mulige permutationer af listen.

## Permutationstest {#permutationstest}

I dette afsnit gives en forklaring af, hvad en permutationstest er. Afsnittet er skrevet på baggrund af [@MathStat, side 54].

Antag, at en tilfældig stikprøveudtagning af en population kan udtrykkes ved $X = [x_1, x_2, \ldots, x_n]$. Der opstilles en nulhypotese $H_0$ og en alternativ hypotese, $H_1$, der er relevante at undersøge. Der kan så vælges en teststørrelse at undersøge for at teste validiteten af $H_0$. Værdien af denne teststørrelse er givet ved $S_{obs}$ for stikprøven.

En permutationstest går ud på at forsøge at måle evidens imod $H_0$, som i en almindelig t-test. Dette gøres ved at beregne teststørrelsen for samtlige permutationer af $X$. Denne mængde af permutationer er givet ved $\Pi_X = \{X_{\pi(1)}, X_{\pi(2)}, \ldots X_{\pi(m)} \}$, hvor $m$ er antallet af mulige permutationer af $X$. Teststørrelsen for den $i$'te permutation benævnes $S_{\pi_i}$.

Ved nu at undersøge, hvor stor en andel af $S_{\pi_i}$, der har en mindre eller større værdi end $S_{obs}$, findes en en-sidet _p_-værdi for testen. Dette kan skrives som $p_{mindre} = \frac{\# S_{\pi_i} \leq  S_{obs}}{m}$, eller tilsvarende for værdier af $S_{\pi_i}$, der er større end $S_{obs}$. For at få den to-sidede _p_-værdi ganges den mindste af de en-sidede p-værdier med $2$.
$p_{mindre}$ er stor i de tilfælde, hvor $S_{\pi_i}$ ofte er mindre end $S_{obs}$. Ligeledes gør det sig gældende, at $p_{større}$ er stor i de tilfælde, hvor $S_{\pi_i}$ ofte er større end $S_{obs}$.

En begrundelse for, hvorfor p-værdien udregnes på denne måde er, at p-værdien er symmetrisk, og derfor må den mindste af de to en-sidede p-værdier ganget med $2$, angive mængden af evidens imod $H_0$, se figur \@ref(fig:fig-p-bootstrap) for illustration.

```{r fig-p-bootstrap, fig.cap="(A) Fordelingen viser 40% observationer større end teststørrelsen og 60% observationer mindre. (B) Fordelingen viser 98% observationer større end teststørrelsen og 2% observationer mindre.", echo=FALSE}
plot1 <- qdist("norm", p = 0.60, mean = 0, sd = 1, ylab="", xlim = c(-4, 4),  return = c("plot"))
plot1 <- plot1 + theme(legend.position = "none")
plot2 <- qdist("norm", p = 0.02, mean = 0, sd = 1, ylab="", xlim = c(-4, 4), return = c("plot"))
plot2 <- plot2 + theme(legend.position = "none")
plot_grid(plot1, plot2, labels = "AUTO")
```

Permutationstest har den fordel, at den antager meget lidt omkring stikprøven. I særdeleshed antager den hverken tilfældig stikprøveudtagning, eller at populationen, fra hvilken stikprøven stammer, er normalfordelt. Der er dog visse ulemper ved en permutationstest. For det første, skal det antages, at den del af data, der permuteres, er ombyttelig. For det andet er det ikke alle teststørrelser, der kan undersøges ved hjælp af en permutationstest - for eksempel vil middelværdien af samtlige permutationer være lig hinanden. For det tredje bliver antallet af mulige permutationer hurtigt meget stor, når størrelsen af stikprøven stiger. Hvis der for eksempel er $n = 10$ datapunkter i stikprøven, vil der være $10! = 3,628,800$ mulige permutationer af stikprøven.

Netop på grund af ombytteligheden af stikprøven fungerer permutationstests. Hvis stikprøven er ombyttelig, vil hver eneste permutation af stikprøven, inklusiv stikprøven selv, være lige sandsynlige. Dette medfører, at hvis $H_0$ er sand, vil enhver difference imellem $S_{obs}$ og $S_{\pi_i}$ være lille og tilfældig. Hvis værdien for $S_{\pi_i}$ på den måde konkluderes at være væsentlig anderledes end $S_{obs}$, tyder det på, at $H_0$ skal forkastes.

Det store antal af permutationer afhjælpes ved kun at beregne $S_{\pi_i}$ for et passende antal, tilfældigt udvalgte, permutationer af stikprøven, og et acceptabelt resultat vil stadig blive opnået.

## Uparret permutationstest

Der vil nu vises et eksempel på, hvordan permutationstest kan anvendes som en hypotesetest. Antag, at det ønskes undersøgt, om middelværdien af to stikprøver er signifikant forskellige. Den opstillede nulhypotese bliver $H_0 : \mu_1 = \mu_2$, og den alternative hypotese bliver $H_1 : \mu_1 \neq \mu_2$.

Der vil blive udtrukket to stikprøver fra den samme betafordeling, der vises på figur \@ref(fig:permhist).

```{r}
set.seed(29)

n <- 100
alfa1 <- 8
beta1 <- 2
stik1 <- rbeta(n, alfa1, beta1)
stik2 <- rbeta(n, alfa1, beta1)

mean_difference <- abs(mean(stik1) - mean(stik2))
```

```{r permhist, echo = FALSE, fig.cap = "To stikprøver udtrukket fra den samme betafordeling med parameterne alpha = 8 og beta = 2."}
par(mfrow = c(1,2))
hist(stik1, main = "", xlab = "", ylab = "Antal observationer")
hist(stik2, main = "", xlab = "", ylab = "Antal observationer")
```

Teststørrelsen vil i dette tilfælde være forskellen mellem stikprøvernes middelværdi, $S_{obs} = |\hat{\mu}_1 - \hat{\mu}_2|$. Den observerede teststørrelse ses at være ```r mean_difference```.  Hvorvidt denne forskel er signifikant, kan nu undersøges ved at beregne forskellen i middelværdi for samtlige permutationer af stikprøverne. Observationerne fra hver stikprøve vil blive forenet i en enkelt stikprøve, som der vil permuteres udfra.

I nedenstående kode udføres der $100$ permutationer på den forenede stikprøve. Den forenede stikprøve har en størrelse på $N = 200$. I hver permutation udtrækkes de første $100$ observationer til at være den permuterede stikprøve ```permuteret_stik1``` , mens de sidste $100$ observationer bliver til den permuterede stikprøve ```permuteret_stik2```. Derefter udregnes den absolutte forskel i middelværdien mellem de nye permuterede stikprøver, i alt $100$ gange, en for hver permutation. 

```{r}
mean_list <- c()
forenet_stik <- c(stik1, stik2)

for(i in 1:100){
  permuteret_forenet_stik <- gtools::permute(forenet_stik)
  permuteret_stik1 <- head(permuteret_forenet_stik, 100)
  permuteret_stik2 <- tail(permuteret_forenet_stik, 100)
  
  mean_list[i] <- abs(mean(permuteret_stik1) - mean(permuteret_stik2))
}
head(mean_list, 3)
```

I outputtet _head(mean_list, 3)_ ses et eksempel på tre af middelværdierne. På figur \@ref(fig:permmeanhist) illusteres fordelingen af alle permutationernes teststørrelser.

```{r permmeanhist, fig.cap = "Permutationsfordelingen af teststørrelserne. Den blå linje viser den originale observerede forskel i middelværdierne."}
hist(mean_list, main = "", ylab = "Antal observationer", xlab = "Forskel i middelværdier")
abline(v = mean_difference, col = "blue")
```

Nu kan p-værdien beregnes, ved at udregne hvor mange gange den observerede forskel mellem middelværdierne på hver permutationstest er større end den originale observerede forskel. Denne værdi divideres derefter med antallet af permutationer. Dette gøres i nedenstående kodestykke. 
```{r}
stoerre_vaerdier <- 0
lavere_vaerdier <- 0

for(i in 1:length(mean_list)){
  if(mean_list[i] >= mean_difference){
    stoerre_vaerdier <- stoerre_vaerdier + 1
  }
}

p_stoerre <- stoerre_vaerdier/length(mean_list)

for(i in 1:length(mean_list)){
  if(mean_list[i] <= mean_difference){
    lavere_vaerdier <- lavere_vaerdier + 1
  }
}

p_lavere <- lavere_vaerdier/length(mean_list)

p_tosidet <- min(2*p_stoerre, 2*p_lavere)
p_tosidet
```

Med en tosidet _p_-værdi på ```r p_tosidet```, er der ikke noget belæg for at forkaste nulhypotesen.

__Type-I fejl__

Antallet af type-I fejl, der opstår i en uparret permutationstest kan undersøges ved at se, hvor mange gange $H_0$ forkastes, selvom $H_0$ er sand. Antallet af type-I fejl bør svare til det valgte signifikansniveau, [@ASTAbog, s. 156-157].

I koden nedenfor bestemmes antallet af type-I fejl for en uparret permutationstest.

```{r}
konf_niveau <- 0.95

type_1_fejl <- replicate(reps, {
  
  stik1 <- rbeta(n, alfa1, beta1)
  stik2 <- rbeta(n, alfa1, beta1)
  samlet_stik <- c(stik1, stik2) 
  
  mean_difference <- abs(mean(stik1) - mean(stik2))
  mean_list <- c()
  
  for(i in 1:(n*2)){
    permuteret_samlet_stik <- gtools::permute(samlet_stik)
    permuteret_stik1 <- head(permuteret_samlet_stik, n)
    permuteret_stik2 <- tail(permuteret_samlet_stik, n)
  
    mean_list[i] <- abs(mean(permuteret_stik1) - mean(permuteret_stik2))
  }
  
  stoerre_vaerdier <- 0
  for(i in 1:length(mean_list)){
    if(mean_list[i] >= mean_difference){
     stoerre_vaerdier <- stoerre_vaerdier + 1
   }
  }
  
  p_stoerre <- stoerre_vaerdier/length(mean_list)
  
  mindre_vaerdier <- 0
  for(i in 1:length(mean_list)){
    if(mean_list[i] >= mean_difference){
     mindre_vaerdier <- mindre_vaerdier + 1
   }
  }

  p_lavere <- lavere_vaerdier/length(mean_list)

  p_tosidet <- min(2*p_stoerre, 2*p_lavere)
  
  type1fejl <- p_tosidet > 1 - konf_niveau
  return(type1fejl)
})

fejltable <- table(type_1_fejl)
fejltable
```

I alt forkastes $H_0$ fejlagtigt i ```r unname(fejltable[1])```$\%$ af tilfældene, hvilket stemmer overens med det valgte signifikansniveau. 

## Parret permutationstest

Ligesom permutationstest kan bruges til at lave en uparret hypotesetest, kan den også bruges til en parret. Fremgangsmåden er det samme, bortset fra, at det er hvert koordinatpar $(x_i, y_i)$ i stikprøven $Z = ((x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n))$, der permuteres.

I nedenstående kode, vises et eksempel på en parret permutations-test for forskel i middelværdi, der gør brug af pakken ```wPerm```.

```{r, tidy=FALSE}
library(wPerm)
reps <- 100
n <- 100
permuteringer <- 1000

p_reps <- replicate(reps, {
  stik1 <- rgamma(n, shape = 10, rate = 2)
  stik2 <- rgamma(n, shape = 4, rate = 13)
  
  test <- wPerm::perm.paired.loc(x = stik1, y = stik2,
                                  parameter = mean,
                                  alternative = "two.sided",
                                  R = permuteringer)
  
  p_vaerdi <- test$p.value
})

p_vaerdi_parret <- mean(p_reps)
p_vaerdi_parret
```

Med en _p_-værdi på ```r p_vaerdi_parret``` kan nulhypotesen forkastes, da der er evidens for, at den ikke er korrekt.



