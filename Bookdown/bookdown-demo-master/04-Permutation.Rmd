```{r, include = FALSE}
library(mosaic)
library(SimDesign)
```
<!-- # Resampling-metoder -->

<!-- I de følgende to underafsnit beskrives to metoder, der er yderst relevante når der arbejdes med statistik. Først vil der ses på permutationstest, og hvordan, permutationer af data kan udnyttes i forskellige test. Derefter vil der blive redegjort for en resampling-metode kaldet bootstrap, hvis anvendelser, der vil undersøges nærmere senere i rapporten. -->

# Permutationstest

I afsnit \@ref(t-test) blev der redegjort for visse antagelser, der skal være opfyldt, for at en t-test giver retvisende resultater. Ligeledes blev der i afsnit \@ref(t-test2) vist hvorledes en t-tests resultater kan være misvisendende, hvis stikprøverne ikke er normalfordelte. 
I dette afsnit vil der redegøres for en løsning til dette problem. Hvis antagelserne ikke er opfyldte, og en t-test ikke kan anvendes, kan der udnyttes permutationstest. Først vil der gives en kort introduktion til permutationer, herefter en forklaring af, hvad en permutationstest er, og til sidst et praktisk eksempel.

## Permutationer

I dette afsnit defineres permutationer, og der gives et kort eksempel på en permutation af en ordnet liste af tre elementer. Afsnittet er skrevet på baggrund af [@Permutationer].

Givet en ordnet liste, $X = [x_1, x_2, \ldots, x_n ]$, er en permutation, $\pi$, en omarrangering af listens elementer, $X_\pi = [x_{\pi(1)}, x_{\pi(2)}, \ldots, x_{\pi(n)}]$. Antallet af mulige permutationer af en ordnet liste, $X$, af længde $n$, er givet ved $n!$.

Som eksempel, er en mulig permutation, $\pi_1$, af $A = [1, 2, 3]$ givet ved $A_{\pi_1} = [2, 1, 3]$, og der er i alt $|A| = 3! = 1 \cdot 2 \cdot 3 = 6$ mulige permutationer af listen.

## Test ved hjælp af permutationer

I dette afsnit gives en forklaring af, hvad en permutationstest er. Afsnittet er skrevet på baggrund af [@Permutationstest].

Antag, at en tilfældig stikprøveudtagning af en population kan udtrykkes ved $X = [x_1, x_2, \ldots, x_n]$. Der opstilles en nulhypotese $H_0$ og en alternativ hypotese, $H_1$, der er relevante at undersøge. Der kan så vælges en teststørrelse at undersøge for at teste validiteten af $H_0$. Værdien af denne teststørrelse er givet ved $S_{obs}$ for stikprøven.

En permutationstest går ud på at forsøge at måle evidens imod $H_0$, som i en almindelig t-test. Dette gøres ved at beregne teststørrelsen for samtlige permutationer af $X$. Denne mængde af permutationer er givet ved $\Pi_X = \{X_{\pi(1)}, X_{\pi(2)}, \ldots X_{\pi(m)} \}$, hvor $m$ er antallet af mulige permutationer af $X$. Teststørrelsen for den $i$'te permutation benævnes $S_{\pi_i}$.

Ved nu at undersøge, hvor stor en andel af $S_{\pi_i}$, der har en mere ekstrem værdi end $S_{obs}$, findes en _p_-værdi for testen. Dette kan skrives som $p = \frac{\# S_{\pi_i}~ \text{mere ekstrem end}~ S_{obs}}{m}$.

Denne form for test har den fordel, at den antager meget lidt omkring stikprøven. I særdeleshed antager den hverken tilfældig stikprøveudtagning, eller at populationen, fra hvilken stikprøven stammer, er normalfordelt. Der er dog visse ulemper ved en permutationstest. For det første, skal det antages, at den del af data, der permuteres, er ombyttelig. For det andet er det ikke alle teststørrelser, der kan testes ved hjælp af en permutationstest - for eksempel vil middelværdien af samtlige permutationer være lig hinanden. For det tredje bliver antallet af mulige permutationer hurtigt meget stor, når størrelsen af stikprøven stiger - hvis der for eksempel er $n = 10$ datapunkter i stikprøven, vil der være $10! = 3,628,800$ mulige permutationer af stikprøven.

Netop på grund af ombytteligheden af stikprøven, fungerer permutationstests. Hvis stikprøven er ombyttelig, vil hver eneste permutation af stikprøven, inklusiv stikprøven selv, være lige sandsynlige. Dette medfører, at hvis $H_0$ er sand, vil enhver difference imellem $S_{obs}$ og $S_{\pi_i}$ være lille og tilfældig. Hvis værdien for $S_{obs}$ på den måde konkluderes at være væsentlig anderledes, tyder det på, at $H_0$ skal forkastes.

Det store antal af permutationer afhjælpes ved kun at beregne $S_{\pi_i}$ for et passende antal, tilfældigt udvalgte, permutationer af stikprøven, og et acceptabelt resultat vil stadig blive opnået.

__Eksempel__

Der vil nu vises et eksempel på hvordan permutationstest kan anvendes som en hypotesetest. Antag, at det ønskes undersøgt, om middelværdien af en to stikprøver er signifikant anderledes. Den opstillet nulhypotese bliver $H_0 : \mu_1 = \mu_2$, og den alternative hypotese bliver $H_1 : \mu_1 \neq \mu_2$.

Der vil blive udtrækket to stikprøver fra den samme betafordeling, der vises på figur \@ref(fig:permhist).

```{r}
set.seed(29)

n = 100
stik1 <- rbeta(n, 8, 2)
stik2 <- rbeta(n, 8, 2)

mean_difference <- abs(mean(stik1) - mean(stik2))
```

Den obsereveret forskel i middelværdien mellem de to stikprøver ses at være ```r mean_difference```.

```{r permhist, fig.cap = "To stikprøver udtrukket fra den samme betafordeling med parameterne alpha = 8 og beta = 2."}
par(mfrow = c(1,2))
hist(stik1, main = "", xlab = "", ylab = "Antal observationer")
hist(stik2, main = "", xlab = "", ylab = "Antal observationer")
```

Den obsereveret forskel i middelværdien mellem de to stikprøver ses at være ```r mean_difference```.
Teststørrelsen vil i dette tilfælde være forskellen mellem stikprøvernes middelværdi, $S_{obs} = |\hat{\mu}_1 - \hat{\mu}_2|$. Hvorvidt denne forskel er signifikant kan nu undersøges ved at beregne forskellen i middelværdi for samtlige permutationer af stikprøverne. Observationerne fra hver stikprøve vil blive forenet i en enkelt stikprøve, som der vil permuteres udfra.

I nedenstående kode udføres der 100 permutationer på den forenet stikprøve, med en størrelse på i alt $n = 200$. I hver permutation udtrækkes de første 100 observationer til at være en permuteret stikprøve 1, mens de sidste 100 observationer bliver til den permuteret stikprøve 2.
Derefter udregnes den absolutte forskel i middelværdien mellem de nye permuteret stikprøver, i alt 100 gange, en for hver permutation. 

```{r}
library(gtools)

mean_list <- c()
forenet_stik <- c(stik1, stik2)

for(i in 1:100){
  permuteret_forenet_stik <- permute(forenet_stik)
  permuteret_stik1 <- head(permuteret_forenet_stik, 100)
  permuteret_stik2 <- tail(permuteret_forenet_stik, 100)
  
  mean_list[i] <- abs(mean(permuteret_stik1) - mean(permuteret_stik2))
}
head(mean_list, 3)
```

I outputtet _head(mean_list, 3)_ ses et eksempel på tre af middelværdierne, som der er i alt 100 af.

Nu kan p-værdien beregnes, ved at udregne hvor mange gange den observeret forskel mellem middelværdierne på hver permutationstest er større end den originale obserevet forskel. Denne værdi divideres derefter med antallet af permutationer der er udført i alt. Dette gøres i nedenstående kodestykke. 
```{r}
extreme_values <- 0

for(i in 1:length(mean_list)){
  if(mean_list[i] >= mean_difference){
    extreme_values <- extreme_values + 1
  }
}
p_value <- extreme_values/length(mean_list)
p_value
```

Med en p-værdi på ```r p_value```, er der ikke noget belæg for at forkaste nulhypotesen.

__Antal type-I fejl__

#type 1 fejl - Simulere stikprøver hvor nulhypoteses passer. Undersøg hvor mange gange jeg forekaster (Burde gerne være 5 % af gangene)

Antallet af type-I fejl der opstår i en permutationstest kan undersøges ved at se hvor mange gange $H_0$ forkastes, selvom $H_0$ er sand. I virkeligheden burde antallet af type-I fejl svare til det valgte signifikansniveau, [@ASTAbog, s. 156-157].

Processen for at finde antallet af type-1 fejl er den samme som i det forrige eksempel. Der udt
Den opsatte nulhypotese vil være 
Først vil der trækkes to stikprøver fra den samme betafordeling, hvor n

```{r}
res <- replicate(1000, {
  
  n = 10
  stik3 <- rbeta(n, 8, 2)
  stik4 <- rbeta(n, 8, 2)
  samlet_stik <- c(stik3, stik4)
  
  mean_difference <- abs(mean(stik3) - mean(stik4))
  perm_samples <- matrix(0, nrow = 10, ncol = 10)
  mean_list <- c()
  for(i in 1:10){
    perm_samples[,i] <- sample(samlet_stik, size = 10, replace = FALSE)
  }

  mean_list <- c()
  
  for(i in 1:10){
    mean_list[i] <- abs(mean(perm_samples[1:5, i]) - mean(perm_samples[6:10, i]))
  }
  
  extreme_values <- 0
  
  for(i in 1:length(mean_list)){
    if(mean_list[i] >= mean_difference){
     extreme_values <- extreme_values + 1
   }
  }
  p_value <- extreme_values/length(mean_list)
  
  
  type1fejl <- p_value > 0.05
  return(type1fejl)
})
table(res)
```




