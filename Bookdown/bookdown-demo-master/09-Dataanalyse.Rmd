# Dataanalyse

<!-- 1. Simulering af data (evt. ved hjælp af LCG og BM).  -->

<!-- 2. Eftervise, at hvis ens antagelser ikke er opfyldt, så får man de misvisende resultater, men man kan udnytte f.eks. bootstrap som vil give det rigtige resultat.  -->

<!-- 3. Sammenligning af parametrisk og ikke-parametrisk bootstrap.  -->

## Simulere data 

Til dataanalysen skal der simuleres populationer.

Populationer:
Normalfordeling. *

```{r, echo=FALSE}
pop_norm <- rnorm(n = 100000, mean = 0, sd = 1)
hist(pop_norm)
```

```{r,echo=FALSE}
stik_norm <- sample(x = pop_norm, size = 100)
hist(stik_norm)
```

```{r}
mean(pop_norm)
sd(pop_norm)
mean(stik_norm)
sd(stik_norm)
```

```{r}
boot_norm <- replicate(10000, mean(sample(stik_norm, size = 100, replace = TRUE)))
hist(boot_norm)
mean(boot_norm)
```






Skæv fordeling. *
Bimodal fordeling.
Uniform fordeling.
T-fordeling i forhold til antal frihedsgrader.

Måske er 2 populationer nok. En der fungerer, en der fejler.

## Inferens

Når almindelig statistisk inferens fejler, er det fordi antagelserne ikke er opfyldt. 

Population -> Almindelig statistisk inferens (middelværdi og standardfejl) -> Yay
Population -> Almindelig statistisk inferens (middelværdi og standardfejl) -> Nay -> Bootstrap -> Yay
Population -> Almindelig statistisk inferens (middelværdi og standardfejl) -> Nay -> Bootstrap -> Nay

Konfidensintervaller 

## Parametrisk vs ikke-parametrisk

Hvad er forskellen på parametrisk og ikke-parametrisk
Hvornår kan de hver anvendens

Andre former for bootstrap der skal kigges på?

## Resultater

Diskutere resultater af dataanalysen?

Er P-hacking relevant for bootstrap?
