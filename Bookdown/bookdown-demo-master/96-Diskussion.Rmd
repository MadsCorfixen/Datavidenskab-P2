```{r, echo=FALSE}
set.seed(31415)
```

# Diskussion

I dette afsnit vil nogle relevante resultater og opdagelser fra rapporten diskuteres.

En væsentlig faktor, som ville have forbedret projektet samt analyserne, er betydeligt bedre computerkraft. I større analyser, hvor antal gentagelser har været essentielle for præcise resultater, har projektet været nødsaget til at reducere disse gentagelser, da computerkraften ikke var tilstrækkelig og derved medført lange simuleringsanalyser. Dette giver sig blandt andet til udtryk i rapporten ved antallet af bootstrap-stikprøver, der bliver udtaget. Selvom der i afsnit \@ref(bootstrap) anbefales et antal bootstrap-stikprøver på $10,000$, er der i rapporten valgt at reducere antallet af bootstrap-stikprøver i nogle tilfælde. Dette kunne give anledning til større usikkerhed i de opnåede resultater, da et for lille antal bootstrap-stikprøver kan medføre, at fordelingen af bootstrap-stikprøvernes estimater ikke tilnærmer sig fordelingen af stikprøveestimatet jævnfør figur \@ref(fig:fig-boot-fordeling).   

Når en population er lille nok kan alle bootstrap-stikprøver og permutationer ( _resamples_ ) bestemmes deterministisk. I praksis er stikprøvestørrelsen typisk for stor til, at dette er muligt, og derfor tages en tilfældig delmængde af mulige _resamples_. Dette kaldes for Monte Carlo simulering. Ved brug af denne form for _resampling_ vil der være en uønsket variabilitet, hvilket kan løses ved at øge antallet af _resamples_. Derfor, når computerkraften ikke kan klare et stort nok antal _resamples_, skaber det en variabilitet for hver gang metoden bliver kørt, [@MathStat, s. 134-135].

Der blev i rapporten undersøgt andelen af type-I fejl, for både permutationstest og bootstrap-test, tilsvarende blev dog ikke undersøgt for type-II fejl. Type-II fejl er nært umulige at afdække, da det afhænger af mange variabler såsom stikprøvestrørrelsen og populationens parametre. Derfor blev andelen af type-II fejl ikke undersøgt yderligere, da det kun ville have givet information for de specifikke tilfælde, hvilket ikke giver mening i den teoretiske tilgang som rapporten beskæftiger sig med.  

I kapitel \@ref(t-test2) blev det vist, at en uparret t-tests konfidensinterval for ikke-normalfordelte stikprøver kunne anses for at være misvisende i forhold til dets dækningsgrad. En af antagelserne for t-testen er, at populationen, som stikprøverne (eller stikprøven) stammer fra, er normalfordelt, som i dette tilfælde ikke blev overholdt. En observation, der blev gjort i forbindelse med undersøgelsen af den uparrede t-test var, at for at få uholdbare resultater, krævede det to forholdsvist skæve, men ikke sammenlignelige, stikprøver. Var stikprøverne i kapitel \@ref(t-test2) i stedet udtrukket fra to fordelinger, der lignede hinanden, ville dækningsgraden have været forholdsvis tæt på de $95\%$, som set i eksemplet nedenfor.

__Eksempel__

I dette eksempel påvises dækningsgraden for to stikprøver udtrukket fra to forskellige betafordelinger ved hjælp af en t-test. Den ene stikprøve er udtrukket fra en betafordeling med $\alpha = 8$ og $\beta = 2$. Den anden stikprøve er udtrukket fra en betafordeling med $\alpha = 2$ og $\beta = 8$.

```{r, echo=FALSE}
middel1 <- 8/(8+2)
middel2 <- 2/(8+2)

sand_dif1 <- abs(middel1 - middel2)


Daekningsgrad <- replicate(10000, {
  x1 <- rbeta(20, 8, 2)
  x2 <- rbeta(20, 2, 8)

  t_res <- t.test(x1, x2, alternative = "two.sided", conf.level = 0.95)

  konfinterval <- t_res$conf.int

  konfinterval[1L] <= sand_dif1 & konfinterval[2L] >= sand_dif1
})

tf1 <- table(Daekningsgrad)
tf1
```

For to stikprøver udtrukket fra hver deres betafordeling, en venstreskæv og en højreskæv, ses en dækningsgrad på konfidensintervallet fra t-testen på ```r tf1[2]/100```$\%$, hvilket er passende tæt på de antagede $95\%$. Derfor blev der i rapporten udtaget stikprøver fra to forskellige fordelinger, henholdsvis en beta- og gammafordeling.

Dækningsgraden af t-testens konfidensintervaller er robust på trods af, at populationerne ikke er normalfordelte. T-testen viser sig altså at være robust overfor overtrådte antagelser, og dette må skyldes den centrale grænseværdisætning, CLT (fra engelsk _central limit theroem_). 

CLT medfører, at fordelingen af stikprøvemiddelværdierne tilnærmelsesvist ligner en normalfordeling. Selv ved relativt lave stikprøvestørrelser, $n = 5$, er dette aktuelt, [@ASTAbog, s. 93, figur 4.15]. At komme ud for en situation, hvor der estimeres middelværdier som i denne rapport, uden at CLT vil have en indflydelse, er usandsynligt. Dette er en fordel i forhold til t-testen, da den netop antager en normalfordeling.


