```{r, echo=FALSE, message=FALSE}
library(mosaic)
library(boot)
set.seed(31415)
```

## Bootstrap-standardfejl {#boot-standardfejl}

Der vil i dette afsnit beskrives, hvordan standardfejl af en stikprøve kan udregnes ved hjælp af bootstrap. Udregnes standardfejlen på denne måde, kaldes den for bootstrap-standardfejlen. I det efterfølgende afsnit vil standardfejlen inddrages i beregningen af konfidensintervallet for en bootstrap-stikprøve. Det følgende afsnit er primært skrevet på baggrund af [@TDSBootstrap].

Standardafvigelsen for en estimator beskrives som estimatorens standardfejl. Standardfejlen er et udtryk for, hvor stor en afvigelse der er fra populationens parameter til stikprøvens estimat. Jo mindre standardfejlen er, desto mindre er afvigelsen mellem estimatet og parameteren. Som udgangspunkt vil en stikprøves estimat aldrig være lig populationens parameter, fordi der ved udtagning af en stikprøve, i hvert tilfælde vil være variabilitet. Standardfejlen er et mål for denne variabilitet.

Som eksempel vil standardfejlen for estimatet af middelværdien, $\hat{\mu}$, være $\text{se}(\hat{\mu}) = \frac{\sigma}{\sqrt{n}}$.

Når der arbejdes med data udover det teoretiske, vil standardafvigelsen for populationen, $\sigma$, altid være ukendt. Derfor bruges stikprøvens estimat for standardafvigelsen, $S$ til at beregne den estimerede standardfejl, $\hat{\text{se}}$. 

Som eksempel vil den estimerede standardfejl for estimatet af middelværdien, $\hat{\mu}$, være  $\hat{\text{se}}(\hat{\mu}) = \frac{S}{\sqrt{n}}$, hvor $S = \sum_{i=1}^{n} \frac{(x_i - \hat{\mu})^2}{n - 1}$ er stikprøvens standardafvigelse for middelværdien, og $n$ er størrelsen på stikprøven.

Dog er dette ikke altid ligetil i virkeligheden. Oftest er der ikke tilstrækkelige informationer om populationen eller fordeligen af denne. Samtidig kræver det, at der er nogle specifikke krav, som er opfyldt. Disse problemer kan undgås ved at benytte bootstrap til at estimere bootstrap-standardfejlen, givet ved nedstående formel.

$$se(\hat{\theta}) = \sqrt{\frac{1}{B-1}\sum_{b=1}^{B}(\hat{\theta_b^*} - \bar{\theta} )^2}$$

Hvor $\hat{\theta}$ er stikprøvens estimat for den ønskede parameter, $B$ er antal bootstrap-stikprøver, $\hat\theta_b^*$ er estimatet for den $b$'te bootstrap-stikprøve og $\bar{\theta} = (\frac{1}{B}) \sum_{b=1}^{B}\hat{\theta_b^*}$, [@BootMiracle].

__Eksempel__ 

I kodestykket nedenfor udtages en tilfældig stikprøve fra en standard normalfordelt population. Først udregnes standardfejlen for stikprøven. Derefter laves $10,000$ bootstrap-stikprøver, som benyttes til at beregne stikprøvens bootstrap-standardfejl. Til sidst sammenlignes disse to estimater.

```{r}
n <- 1000

stik <- rnorm(n, mean = 0, sd = 1)
SD_stik <- sd(stik)
SE_stik <- SD_stik/sqrt(n)

B <- 10000

middel_funk <- function(stik, i){mean(stik[i])} # Estimator

Boot_stik <- boot::boot(data = stik, statistic = middel_funk, R = B) # Bootstrap-stikprøver
SE_boot <- sd(Boot_stik$t) # Standardfejlen for bootstrap-stikprøverne

# Procentvis afvigelse mellem normal standardfejl og bootstrap-standardfejl
diff_procent <- ((abs(SE_stik - SE_boot))/SE_stik) * 100
```

Fra eksemplet fås, at bootstrap-standardfejlen for stikprøven er $se(\hat{\theta})=$```r round(SE_boot, 4)```, hvilket approksimerer stikprøvens standardfejl på $\text{se}(\hat{\mu})=$```r round(SE_stik, 4)```, med en forskel i dette tilfælde på ```r round(diff_procent, 3)```$\%$. Hvis der opstår en situation, hvor der ikke er en simpel måde, hvorpå det er muligt at udregne standardfejlen, kan bootstrap-standardfejlen altså udnyttes, da en forskel på ```r round(diff_procent, 3)```$\%$ ikke er signifikant. 
