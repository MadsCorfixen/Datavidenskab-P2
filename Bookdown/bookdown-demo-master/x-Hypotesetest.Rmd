```{r include=FALSE, MESSAGE = FALSE}
library(mosaic)
```

## Hypotesetest

En hypotesetest er givet ved en formodning, derved hypotese, om en given population forholder sig på en bestemt måde, hvilket der undersøges. Heraf opstilles to hypoteser. En nulhypotese, $H_0$, og en alternativ hypotese $H_1$. Nulhypotesen er den antagelse der er taget, hvor den alternative hypotese påviser at det ikke er tilfældet, og derved at noget andet er gældende. 

På baggrund af en normalfordeling er det muligt at lave en hypotesetest ud fra følgende med en t-test. [@ASTA-HYPO]

Grunden til at benytte en hypotesetest er, at undersøge hvorvidt differencen på $H_0$ og den observerede værdi fra datasættet er sandsynlig. Sansynligheden for en difference er stor eftersom, der arbejdes på en stikprøve og ikke selve populationen.

En hypotesetest evaluerer sandsynligheden for mulige udfald, for på den måde at kunne forkaste $H_0$ eller ej. [@HvorforHYPO]

For at kunne undersøge hvorvidt der er en signifikant forskel mellem stikprøven og og hypotesen benyttes en signifikanstest. For at kunne evaluere om en diffenrence er signifikant opstilles testtørrelsen og _p_-værdien findes.

Teststørrelsen sammenligner stikprøven med den forventede værdi fra $H_0$, og indikerer hvor mange standardafvigelser stikprøven er fra $H_0$. Afhængigt af hypotesetest benyttes forskellige teststørrelser. T-test benytter t-teststørrelse, hvor ANOVA benytter F-teststørrelse osv. [@TEST-HYPO]

Teststørrelsen findes ofte ved $T(\hat\theta, \theta_0) =$ "Antallet af standardafvigelser fra $\hat\theta$ til $\theta_0$", hvor $\hat\theta$ er den estimerede værdi og $\theta_0$ er den forventede værdi fra $H_0$. Denne værdi kendetegnes ved den observerede værdi af t, $t_{obs}$.
Det vil være meget usandsynligt at $\hat\theta$ er mere end 3 standardafvigelser fra $\theta_0$, hvilket påpeger, at $\theta_0$ højst sandsynligt ikke er populationens korrekte værdi. [@ASTA-HYPO]

En illustration af teststørrelsens betydning ved en normalfordeling kan ses i figuren herunder.

```{r, figur-Hypotesetest, out.width='75%', fig.align='center', fig.cap = "Teststørrelsens indflydelse på nulhypotesen", echo = FALSE}
knitr::include_graphics('images/HippoHyppo.jpg')
```

Derudover benyttes testtørrelsen til at udregne _p_-værdien. Størrelsen af teststørrelsen påvirker _p_-værdien, og hvis testtørrelsen bliver for stor medfører det, at _p_-værdien bliver lille nok til at kunne forkaste $H_0$. Altså, jo mindre _p_-værdien er, des mindre stoles der på $H_0$. Hvis $p<\alpha$ forkastes $H_0$, hvor $p>\alpha$ ikke giver grundlag til at forkaste $p<\alpha$. Normalt arbejder man med et signifikansniveau på 5%, $\alpha=0.05$. Dog er der intet fast signifikansniveau og det kunne ligeså vel være 10% eller 1%. Betydningen heraf diskuteres kort sidst i afsnittet under fejltyper. [@ASTA-HYPO]

### Hypotesetest på normalfordeling
På baggrund af en normalfordeling er det muligt at lave en hypotesetest ud fra følgende med en t-test. [@ASTA-HYPO] 

* Udregner estimater for parametrene af populationen, middelværdien, $\hat \mu = \bar y$ og standardafvigelsen, $\hat \sigma = s$ ud fra $n$ observationer.

* En nulhypotese: $H_0 : \mu = \mu_{forventet}$ og en alternativ hypotese: $H_a : \mu \neq \mu_{forventet}$.

* Udregne den observerede teststørrelse, $t_{obs} = \frac{\bar y - \mu_o}{\frac{s}{\sqrt{n}}}$.

* Frihedsgrader, $df = n-1$.

* *P*-værdien, som kan slåes op eller findes i r ved ```2 * (1 - pdist("t", q = t_obs, df = n-1))```.

* Derudover sættes et signifikansniveau, $\alpha$, som vuderer hvorvidt $H_0$ forkastes eller ej.

```{r include=FALSE}
set.seed(1)
n <- 10
forventet_middelvaerdi <- 0
xdata <- rnorm(n, forventet_middelvaerdi, 1)
x_middelvaerdi <- mean(xdata)
```

```{r, echo=FALSE}
hist(xdata,
     main="Simuleret Z-fordeling - norm(0,1) * 10" ,
     ylab="Frekvens",
     xlab="Værdi")
```

Med et normalfordelt datasæt er det muligt at undersøge om observationerne modstrider hypotesen eller ej. Eksempelvis benyttes et datasættet over af ```r n``` observationer med en middelværdi på ```r x_middelvaerdi``` og en forventet middelværdi på ```r forventet_middelvaerdi```, så kan der undersøge om forskellen er signifikant.

```{r}
n <- 10
forventet_middelvaerdi <- 0 # Forventet middelværdi
middelvaerdi <- mean(xdata) # Middelværdi
standardafvigelse <- sd(xdata) # Standardafvigelsen
estimeret_standardfejl <- standardafvigelse/sqrt(n) # Estimeret standardfejl
t_obs <- (middelvaerdi-forventet_middelvaerdi)/estimeret_standardfejl # Observeret teststørrelse
alpha_halve <-  1 - pdist("t", q = t_obs, df = n-1, plot = FALSE)
p <- 2 * alpha_halve
```

```{r include=FALSE}
# Viser hvis forventede mean havde været lavere
forventet_meanx <- -0.5
t_obsx <- (middelvaerdi-forventet_meanx)/estimeret_standardfejl # Observeret teststørrelse
x_p = 2 * (1 - pdist("t", q = t_obsx, df = n-1, plot = FALSE))
```


Eftersom *p*-værdien er ```r p``` $> \alpha=0.05$, forkastes $H_0$ ikke. Havde det derimod været en forventet værdi på ```r forventet_meanx```, ville *p*-værdien blive ```r x_p``` $< \alpha=0.05$, hvilket vil medføre, at $H_0$ forkastes og det vil formodes, at $H_0$ ikke er korrekt for populationen.

T-testen kan kun benyttes på normalfordelinger, eftersom det antages, at stikprøven efterligner en normalfordeling. __FIXME:__ [Noget vi vil kigge på?]

### Fejltyper

Der er risiko for to primære fejl når der foretages en hypotesetest. Den første, type-1 fejl, er hvor $H_0$ forkastes, men i virkeligheden er sand, og den anden, type-2 fejl, er hvor $H_0$ accepteres, men i realiteten er falsk.

En af de primære årsager til disse typer fejl er, hvor signifikansniveauet bliver sat, da dette i nogle tilfælde har stor betydning for, hvorvidt en hypotese bliver forkastet eller ej.

Sandsynligheden for type-1 fejl er lig med det valgte signifikansniveau - i de fleste tilfælde 5%. Sandsynligheden for type-2 fejl er derimod ikke let at præcisere. Dog er der stor sandsynlighed for type-2 fejl, hvis den virkelige sandhed er tæt på hypotesen og lille, hvis den er langt fra. Ligeledes har stikprøvens størrelse indflydelse, eftersom meget data mindsker risikoen for type-2 fejl, hvor der er større risiko ved mindre data. [@Fejltyper]
