## Bootstrap-hypotesetest

```{r, include=FALSE}
library(mosaic)
set.seed(31415)
```

Som nævnt i afsnit \@ref(t-test), skal visse antagelser være opfyldt, for at garantere korrektheden af resultaterne af en t-test, og det efterfølgende resultat af overtrædelsen af disse antagelser, blev vist i kapitel \@ref(t-test2).

Når disse antagelser ikke er opfyldt, kan bootstrap anvendes til at udføre hypotesetest, og i så fald kaldes det i det følgende for en bootstrap-test. I følgende to afsnit gennemgås først fremgangsmåden for en uparret bootstrap-test, og dernæst fremgangsmåden for en parret bootstrap-test.

### Uparret bootstrap-test

I dette afsnit benyttes bootstrap til at lave en uparret hypotesetest på skæve stikprøver.

Lad to uafhængige uparrede stikprøver, $X=[x_{1},~x_{2},~...,~x_{n}]$ og $Y=[y_{1},~y_{2},~...,~y_{m}]$, hvor $X \wedge Y \sim \text{Beta}(2, 8)$, med ens varians være givet på figur \@ref(fig:histhypuparret).

```{r}
n <- 20
m <- 50

stik1 <- rbeta(n, shape1 = 2, shape2 = 8)
stik2 <- rbeta(m, shape1 = 2, shape2 = 8)
```

```{r histhypuparret, echo = FALSE, fig.cap = "To uafhængige uparrede stikprøver"}
par(mfrow = c(1,2))
hist(stik1, main = "", xlab = "Stikprøve 1", ylab = "Antal observationer", ylim = c(0, 20))
hist(stik2, main = "", xlab = "Stikprøve 2", ylab = "Antal observationer", ylim = c(0, 20))
```

Så opstilles der en nulhypotese, $H_0: \mu_{_X} - \mu_{_Y} = 0$, hvor $\mu_{_X}$ og $\mu_{_Y}$ er de sande middelværdier for populationerne, hvorfra stikprøverne blev udtrukket og en alternativ hypotese, $H_1: \mu_{_X} - \mu_{_Y} \neq 0$, samt et signifikansniveau, $\alpha = 0.05$. 

På baggrund af forskellen i de to stikprøvers middelværdi, er det muligt at udregne en teststørrelse ved nedenstående formel.

$$t_{obs} = \frac{(\bar{X}-\bar{Y}) - (\bar{X_0} - \bar{Y_0})}{((s_X^2/n) + (s_Y^2/m))}$$

Hvor $\bar{X_0}$ og $\bar{Y_0}$ er middelværdien for $X$ og $Y$ under $H_0$, og $s$ er standardafvigelsen.

```{r}
t_obs <- ((mean(stik1) - mean(stik2)) - (0)) /
            (sqrt(((sd(stik1))^2 / n)) +
              ((sd(stik2))^2 / m))
t_obs
```

For at udføre bootstrap-testen, forenes de to stikprøver til en samlet stikprøve med størrelsen $n + m$ observationer. Derefter laves en bootstrap-stikprøve af $n + m$ observationer fra den samlede stikprøve. De første $n$ indgange i bootstrap-stikprøven er bootstrap-stikprøven for $X$, og kaldes $X^*$. De resterende $m$ indgange er bootstrap-stikprøven for $Y$, og kaldes $Y^*$. Til sidst udregnes bootstrap-teststørrelsen ved hjælp af nedenstående formel.

$$t^* = \frac{(\bar{X}^*-\bar{Y}^*) - (\bar{X} - \bar{Y})}{((s_{X^*}^2/n) + (s_{Y^*}^2/m))}$$

I alt beregnes der $B$ bootstrap-teststørrelser, [@BootHypo]. Et eksempel på dette udregnes i nedenstående kodestykke.

```{r}
bootstraps <- 1000
boot_t <- replicate(n = bootstraps, {
    
    # Samlede bootstrap-stikprøve
    boot <- sample(x = c(stik1, stik2), replace = TRUE) 
  
    boot_x <- boot[1 : n] # Bootstrap-stikprøve 1
    boot_y <- boot[(n + 1) : (n + m)] # Bootstrap-stikprøve 2
  
    boot_test <- ((mean(boot_x) - mean(boot_y)) -
                    (mean(stik1) - mean(stik2))) /
                      (sqrt(((sd(boot_x))^2 / n)) +
                        ((sd(boot_y))^2 / m))
})
head(boot_t, 3)
```

Ovenfor ses tre af bootstrap-teststørrelserne, og fordelingen af dem kan ses på på figur \@ref(fig:boothypuparret), hvor den observerede teststørrelse er markeret med en blå linje, og bootstrap-teststørrelsernes middelværdi er markeret med en grøn linje.

```{r boothypuparret, echo = FALSE, fig.cap = "Fordelingen af bootstrap-teststørrelserne, hvor den blå linje markerer den observerede teststørrelse, og den grønne linje markerer fordelingens middelværdi."}
hist(boot_t, main = "", ylab = "Antal observationer", xlab = "Bootstrap teststørrelse")
t_boot <- mean(boot_t)
abline(v = t_obs, col = "blue")
abline(v = t_boot, col = "green")
```

Herefter kan _p_-værdien udregnes som ved permutationstest i afsnit \@ref(permutationstest). 

```{r}
antal_ekstreme <- abs(boot_t) >= t_obs

p_vaerdi <- (sum(antal_ekstreme) + 1) / (bootstraps + 1)
p_vaerdi
```

Med en _p_-værdi på ```r round(p_vaerdi, 2)```, kan $H_0$ ikke forkastes, da der ikke er evidens for at middelværdierne for de to populationer er forskellige. Dette resultat stemmer overens med figur \@ref(fig:boothypuparret), da bootstrap-teststørrelsernes middelværdi er tæt på den observerede teststørrelse.

__Eksempel__

Den udførte test kan ved hjælp af R's funktion ```replicate```, gentages mange gange, for at undersøge om resultatet vil blive det samme, ved mange stikprøveudtagninger. Fremgangsmåden for den uparrede bootstrap-test er den samme. Den bliver blot gentaget $100$ gange, og middelværdien af de $100$ _p_-værdier findes.

```{r}
res <- replicate(n = 100, {
  stik1 <- rbeta(n, shape1 = 2, shape2 = 8)
  stik2 <- rbeta(m, shape1 = 2, shape2 = 8)
  t_obs <- ((mean(stik1) - mean(stik2)) - (0)) /
              sqrt(((sd(stik1))^2 / n)) + ((sd(stik2))^2 / m)

  boot_t <- replicate(n = bootstraps, {
  
    boot <- sample(c(stik1, stik2), replace = TRUE)
  
    boot_x <- boot[1 : n]
    boot_y <- boot[(n+1) : (n+m)]
    boot_test <- ((mean(boot_x) - mean(boot_y)) -
                    (mean(stik1) - mean(stik2))) /
                      sqrt(((sd(boot_x))^2 / n)) +
                        ((sd(boot_y))^2 / m)
  })
  
  antal_ekstreme <- abs(boot_t) >= t_obs

  p_vaerdi <- (sum(antal_ekstreme)+1) / (bootstraps + 1)
})

p_vaerdi_uparret <- mean(res)
p_vaerdi_uparret
```

Der ses, at gennemsnittet af _p_-værdierne er lig ```r round(p_vaerdi_uparret, 4)```, hvilket er større end signifikansniveauet. Dermed er der ikke evidens nok til at forkaste nulhypotesen.

### Parret bootstrap-test

I dette afsnit benyttes bootstrap til at lave en parret hypotesetest på skæve stikprøver.

Lad to parrede stikprøver være givet, $X=[x_{1},~x_{2},~...,~x_{n}]$ og $Y=[y_{1},~y_{2},~...,~y_{n}]$.
Der oprettes et tredje datasæt, $Z$, som består af differencerne mellem $x_i$ og $y_i$, $Z = [x_1-y_1,~ x_2-y_2,~...,~x_n-y_n] = [z_1,~z_2,~...,~z_n]$. Ved hjælp af det nye datasæt er det muligt at udregne teststørrelsen, $t_{obs} = \frac{\bar{Z} - \mu_0}{\hat{SE}(Z)}$.

Så opstilles der en nulhypotese, $H_0:~\mu_Z = 0$, hvor $\mu_Z$ angiver den sande middelværdi for $Z$, og en alternativ hypotese, $H_1:~\mu_Z \neq 0$, samt et signifikansniveau, $\alpha = 0.05$. 

Der udtages en bootstrap-stikprøve for $Z$, som betegnes $Z^*$. På baggrund af bootstrap-stikprøven kan der nu udregnes $B$ nye teststørrelser, $t^*_i = \frac{\bar{Z}^*_i - \bar{Z}}{\hat{SE}(Z^*_i)}$, hvor $Z^*_i$ er den $i$'te bootstrap-stikprøve, og $i = 1, 2, \ldots, B$, [@MathStat, s. 106, 124-127, 246].

__Eksempel__

I nedenstående kode, vises et eksempel på en parret bootstrap-test, hvor stikprøverne ikke er fra den samme fordeling.

```{r}
n <- 15

p_reps <- replicate(n = 100, {
  stik1 <- rgamma(n, shape = 10, rate = 2)
  stik2 <- rgamma(n, shape = 4, rate = 13)
  stik_diff <- stik1 - stik2
  obs_t <- (mean(stik_diff)-0)/(sd(stik_diff)/sqrt(n))

  boot_t <- c()
  for(i in seq(1, bootstraps)){
    boot <- sample(stik_diff, n, replace = TRUE)
    boot_t[i] <- (mean(boot)-mean(stik_diff))/(sd(boot)/sqrt(n))
  }
  
  antal_ekstreme <- abs(boot_t) >= obs_t
  
  p_vaerdi <- (sum(antal_ekstreme) + 1) / (bootstraps + 1)
})

p_vaerdi_parret <- mean(p_reps)
p_vaerdi_parret
```

Det ses, at p-værdien er lig ```r p_vaerdi_parret```, hvilket er mindre end signifikansniveauet. Her vil nulhypotesen forkastes, da der er evidens for at differencen ikke er $0$. For at undersøge korrektheden af en bootstrap-test, kan andelen af type-I fejl, som skal svare til signifikansniveauet, beregnes, [@ASTAbog, s. 159-160].

__Type-I fejl__

Antallet af type-I fejl, der opstår i en parret bootstrap-test kan undersøges ved at se, hvor mange gange $H_0$ forkastes, selvom $H_0$ er sand.

I koden nedenfor bestemmes antallet af type-I fejl for en parret bootstrap-test.

```{r, echo=FALSE}
set.seed(31415)
```

```{r}
n <- 20
konf_niveau <- 0.95
sand_middel <- 0

type_1_fejl_boot <- replicate(n = 500, {
  stik1 <- rgamma(n, shape = 8, rate = 2)
  stik2 <- rgamma(n, shape = 8, rate = 2)
  stik_diff <- stik1 - stik2
  obs_t <- (mean(stik_diff)-sand_middel)/(sd(stik_diff)/sqrt(n))

  boot_t <- c()
  for(i in seq(1, bootstraps)){
    boot <- sample(stik_diff, n, replace = TRUE)
    boot_t[i] <- (mean(boot)-mean(stik_diff))/(sd(boot)/sqrt(n))
  }

  antal_ekstreme <- abs(boot_t) >= obs_t

  p_vaerdi <- (sum(antal_ekstreme)+1) / (bootstraps + 1)
  
  andel <- p_vaerdi > 1 - konf_niveau
})

type_1_parret <- table(type_1_fejl_boot)
type_1_parret
```

I alt forkastes $H_0$ fejlagtigt i ```r unname(type_1_parret[1])/5```$\%$ af tilfældene, hvilket ikke stemmer overens med det valgte signifikansniveau.

Selvom det virker godt, at bootstrap laver færre type-I fejl end signifikansniveauet antyder, er det ikke nødvendigvis en fordel. Hvis der laves en hypotesetest, hvor det forventede antal type-I fejl er lig signifikansniveauet, men det faktiske antal er noget andet, kan det lede til forkerte konklusioner. 
