## Bootstrap-hypotesetest

Som nævnt i afsnit \@ref(t-test), skal visse antagelser være opfyldt, for at garantere korrektheden af resultaterne af en t-test, og det efterfølgende resultatet af overtrædelsen af disse antagelser, blev vist i afsnit \@ref(t-test2).

Når disse antagelser ikke er opfyldt, kan bootstrap anvendes til at udføre t-test, og i så fald kaldes det i det følgende for en bootstrap-test. I følgende to afsnit gennemgås først fremgangsmåden for en parret bootstrap-test, og dernæst fremgangsmåden for en uparret bootstrap-test.

### Parret bootstrap-test

Lad to parrede stikprøver være givet, $X=[x_{1},~x_{2},~...,~x_{n}]$ og $Y=[y_{1},~y_{2},~...,~y_{n}]$.
Der oprettes et tredje datasæt, $Z$, som består af differencerne mellem $x_i$ og $y_i$, $Z = [x_1-y_1,~ x_2-y_2,~...,~x_n-y_n] = [z_1,~z_2,~...,~z_n]$. Ved hjælp af det nye datasæt er det muligt at udregne teststørrelsen, $t_{obs} = \frac{\bar{Z} - \mu_0}{\hat{SE}(Z)}$.

Så opstilles der en nulhypotese, $H_0:~\mu = 0$, hvor $\mu$ angiver den sande middelværdi for $Z$, og en alternativ hypotese, $H_1:~\mu\neq 0$, samt et signifikansniveau, $\alpha = 0.05$. 

Der udtages en bootstrap-stikprøve for $Z$ af $n$ observationer med tilbagelægning, som betegnes $Z^*$. På baggrund af bootstrap-stikprøven for $Z$, kan der nu udregnes $B$ nye teststørrelser, $t^*_i = \frac{\bar{Z}^*_i - \bar{Z}}{\hat{SE}(Z^*_i)}$, hvor $Z^*_i = [z^*_{1,i},~z^*_{2,i},~...,~z^*_{n,i}]$, [@BootvsJack, s. 106, 124-127, 246].

_P_-værdien ligger i intervallet $[0,1]$, $p_{tosidet} \in [0,1]$, hvor $p_{mindre} + p_{større} = 1$ . Vælges $\min (p_{mindre}, ~p_{større})$ fås en ensidet _p_-værdien. For at opnå den tosidede _p_-værdi multipliceres der med $2$. Se figur \@ref(fig:fig-p-bootstrap) for illustration.

```{r, include=FALSE}
library(mosaic)
library(cowplot)
```

```{r fig-p-bootstrap, fig.cap="(A) Fordelingen viser 40% observationer større end teststørrelsen og 60% observationer mindre. (B) Fordelingen viser 98% observationer større end teststørrelsen og 2% observationer mindre.", echo=FALSE}
plot1 <- qdist("norm", p = 0.60, mean = 0, sd = 1, ylab="", xlim = c(-4, 4),  return = c("plot"))
plot1 <- plot1 + theme(legend.position = "none")
plot2 <- qdist("norm", p = 0.02, mean = 0, sd = 1, ylab="", xlim = c(-4, 4), return = c("plot"))
plot2 <- plot2 + theme(legend.position = "none")
plot_grid(plot1, plot2, labels = "AUTO")
```

$p_{mindre}$ er lav i de tilfælde, hvor $t^*$ ofte er mindre end $\bar Z$. Ligeledes gør det sig gældende, at $p_{større}$ er lav i de tilfælde, hvor $t^*$ ofte er større end $\bar Z$. Funktionen $\min$ bliver benyttet eftersom der undersøges, hvor ofte mere ekstreme tilfælde optræder end den observerede teststørrelse, [@Hypo_test].

\begin{align}
p_{_{mindre}} &= \frac{\text{antal gange }\{t^*<\bar{Z}\}}{B} \\
p_{_{større}} &= \frac{\text{antal gange }\{t^*>\bar{Z}\}}{B} \\
p_{_{tosidet}} &= \text{min}(2 \cdot p_{_{mindre}},~ 2 \cdot p_{_{større}})
\end{align}

Forkast $H_0$, hvis $\text{p}_{_{tosidet}}<\alpha$.

__Eksempel__

I nedenstående kode, vises et eksempel på en parret bootstrap-test, hvor stikprøverne ikke er fra den samme fordeling.

```{r}
reps <- 100
n <- 15
alfa1 <- 10
beta1 <- 2
alfa2 <- 4
beta2 <- 13
B <- 1000

p_reps <- replicate(reps, {
  stik1 <- rgamma(n, alfa1, beta1)
  stik2 <- rgamma(n, alfa2, beta2)
  stik_diff <- stik1 - stik2
  obs_t <- (mean(stik_diff)-0)/(sd(stik_diff)/sqrt(n))

  boot_t <- c()
  for(i in seq(1, B)){
    boot <- sample(stik_diff, n, replace = TRUE)
    boot_t[i] <- (mean(boot)-mean(stik_diff))/(sd(boot)/sqrt(n))
  }

  antal_mindre <- boot_t <= obs_t
  antal_stoerre <- boot_t >= obs_t

  p_1 <- sum(antal_mindre)/B
  p_2 <- sum(antal_stoerre)/B

  p_vaerdi <- min(2*p_1, 2*p_2)
})

p_vaerdi_parret <- mean(p_reps)
p_vaerdi_parret
```

Der ses altså at p-værdien er lig ```r round(p_vaerdi_parret, 4)```, hvilket er mindre end signifikansniveauet. Her vil nulhypotesen forkastes, da der er evidens for at differencen ikke er $0$.

### Uparret bootstrap-test

Lad to uafhængige uparrede stikprøver, $X=[x_{1},~x_{2},~...,~x_{n}]$ og $Y=[y_{1},~y_{2},~...,~y_{m}]$, med ens varians, være givet.

På baggrund af forskellen i de to stikprøvers middelværdi, er det muligt at udregne en teststørrelse, $\bar{X}-\bar{Y}$.

Så opstilles der en nulhypotese, $H_0: \mu_{_X} = \mu_{_Y}$, hvor $\mu_{_X}$ og $\mu_{_Y}$ er de sande middelværdier for populationerne, hvorfra stikprøverne blev udtrukket og en alternativ hypotese, $H_1: \mu_{_X} \neq \mu_{_Y}$, samt et signifikansniveau, $\alpha = 0.05$. 

Først forenes de to stikprøver til en samlet stikprøve med størrelsen $n+m$ observationer. Derefter laves en bootstrap-stikprøve af $n+m$ observationer med tilbagelægning fra den samlede stikprøve. Herefter udregnes middelværdien af de første $n$ observationer, som kaldes $\hat{X}^*_1$. Desuden udregnes middelværdien af de resterende $m$ observationer, der kaldes $\hat{Y}^*_1$. Til sidst udregnes bootstrap-teststørrelsen $t^*_1=\hat{X}^*_1-\hat{Y}^*_1$, [@BootHypo].

Trin to til fem i ovenstående gentages i alt $B$ gange, hvilket giver $B$ teststørrelser. 

Herefter kan p-værdien udregnes, som antal gange bootstrap-teststørrelsen er mere ekstrem end den observerede teststørrelse. Dette gøres ved at finde den mindste af de to ensidede p-værdier og gange den med $2$, [@Hypo_test].

\begin{align}
p_{_{mindre}} &= \frac{\text{antal gange }\{t^*<\bar{Z}\}}{B} \\
p_{_{større}} &= \frac{\text{antal gange }\{t^*>\bar{Z}\}}{B} \\
p_{_{tosidet}} &= \text{min}(2 \cdot p_{_{mindre}},~2 \cdot p_{_{større}})
\end{align}

Forkast $H_0$, hvis $\text{p}_{_{tosidet}}<\alpha$.

__Eksempel__

Nu vil der vises et eksempel på en uparret bootstrap t-test.

```{r}
reps <- 100
n1 <- 15
n2 <- 30
alfa1 <- 8
beta1 <- 2
alfa2 <- 2
beta2 <- 8
B <- 1000

res <- replicate(reps, {
  stik1 <- rbeta(n1, alfa1, beta1)
  stik2 <- rbeta(n2, alfa2, beta2)

  t_obs <- mean(stik1) - mean(stik2)

  boot_t <- replicate(B, {
  
    boot <- sample(c(stik1, stik2), replace = TRUE)
  
    bootx <- boot[1 : n1]
    booty <- boot[(n1+1) : (n1+n2)]
  
    diffmean <- (mean(bootx) - mean(booty))
  })

  antal_mindre <- boot_t <= t_obs
  antal_stoerre <- boot_t >= t_obs

  p_1 <- sum(antal_mindre)/B
  p_2 <- sum(antal_stoerre)/B

  p_vaerdi <- min(2*p_1, 2*p_2)
})

p_vaerdi_uparret <- mean(res)
p_vaerdi_uparret
```

Der ses altså at p-værdien er lig ```r round(p_vaerdi_uparret, 4)```, hvilket er mindre end signifikansniveauet. Her vil nulhypotesen forkastes, da der er evidens for at differencen ikke er $0$.
