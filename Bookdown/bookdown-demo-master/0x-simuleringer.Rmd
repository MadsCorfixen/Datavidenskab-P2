# Simulering af variabler

Simuleringer er generering af estimater på mulige udfald, og på den måde en efterligne virkeligheden. Formålet er derved at generere tilfældigt estimerede værdier ud fra en model, der simulerer virkeligheden, hvilket muliggør yderligere analyser.

En definition på simulering er;

>A situation or event that seems real but is not real, used especially in order to help people deal with such situations or events. - Cambridge Dictonary [https://dictionary.cambridge.org/dictionary/english/simulation]

Ud fra definitionen, er formålet altså ved simuleringer at efterligne virkeligheden, så de analyser der gøres på baggrund af simuleringerne, kan bruges i virkeligheden når lignende situationer opstår.
Brancher hvor simuleringer er et yderst vigtigt redskab, er i motorsporten. I Formel 1 benytter holdene sig af simulatorer, hvor de genskaber bilerne og derved kan teste nye dele inden de producere dem i virkeligheden for at spare penge. Derved kan de analysere, hvilke forskellige dele der producerer mest _down-force_, uden at skulle teste dem i virkelig. [https://careers.mercedesamgf1.com/facilities/simulator/]

## Simulering i R
Meta-forklaring til afsnittet. Henvises der ikke til noget er kilden: [https://bookdown.org/rdpeng/rprogdatascience/simulation.html]


Simuleringer i R udføres ved at estimere udfald fra en fordeling, hvor der bliver generet pseudo-tilfældige tal.
Disse generede tal forekommer at være tilfældige, men er det reelt set ikke. [https://en.wikipedia.org/wiki/Pseudorandom_number_generator]

Tallene er genereret ud fra et _seed_, som i R bestemmes ved ```set.seed("værdi")```. Genererer man tal ud fra samme _seed_ vil værdierne være identiske.

Fordelinger, som der blandt andet kan simuleres i R, er normalfordelinger, binomialfordelinger og uniforme fordelinger.

En normalfordeling kan simuleres på følgende måde:
```{r}
set.seed(1)
rnorm(10, mean = 0, sd = 1)
```

Først sættes et _seed_ så man kan rekonstruere samme simulering igen. Næste linje startes med at skrive ```rnorm``` hvor "r" står for tilfældigt genererede tal, og "norm" for en normalfordeling. Inde i paranteserne angives antallet af værdier, der skal genereres, som bliver genereret ud fra en middelværdi på 0 og en standardafvigelse på 1. Eftersom middelværdien er 0 og standardafvigelsen er 1, kaldes denne normalfordeling for en standard normalfordeling eller Z-fordeling.

Ligeledes kan man simulere binomialfordelinger og uniforme fordelinger:
```{r}
set.seed(1)
rbinom(10, size = 2, prob = 0.5)
```

Som før sættes et _seed_, og der skrives "r" før fordelingen der simuleres. Ligeledes er første værdi antallet af værdier der skal genereres. __I binomialfordelingen er der angivet _size_, som er antallet af succes/fejl _(1/0)_ repetationer(forklaring)__, hvorimod _prob_ er sandsynligheden for succes.

```{r}
set.seed(1)
runif(10, min = 1, max = 2)
```

Den uniforme fordelingen er derimod angivet med en minimum- og maksimumværdi, hvor der genereres værdier imellem.

### Sample og replicate (Bootstrapping)

Derudover kan der simuleres på baggrund af observeret data. Ved at benytte funktionerne ```sample``` og ```replicate``` kan der dannes nye simuleringer. ```sample``` tager en stikprøve af den observerede data, hvor ```replicate``` kan gentage forskellige stikprøver.
```{r}
set.seed(1)
Z_fordeling <- rnorm(1000, mean = 0, sd = 1)

mean(Z_fordeling)
```
Her eksekveres en Z-fordeling af 1.000 observationer hvor middelværdien, -0,012, printes. Denne middelværdi vil variere afhængigt af det _seed_¨, der benyttes.

Dernæst kan der foretages en ```sample``` af variablen ```Z_fordeling```.

```{r}
set.seed(1)
Z_sample <- sample(Z_fordeling, size = 10, replace = TRUE)

Z_sample
mean(Z_sample)
```
Her fremgår der 10 værdier, som er taget fra ```Z_fordeling```, som gemmes i ```Z_sample```. ```Replace``` gør så de værdier der tages og gemmes i ```Z_sample``` bliver lagt tilbage, og kan derved blive taget igen, så man kan få den samme værdi flere gange.

Derefter er det muligt at gentage disse stikprøver ved brug af ```replicate```
```{r}
set.seed(1)
Z_replicate <- replicate(100, {
  x <- mean(sample(Z_fordeling, size = 10, replace = TRUE))
})
Z_replicate
mean(Z_replicate)
```
Her bliver en stikprøve af ```Z_fordeling``` foretaget 10x100 gange, hvorefter middelværdien på de 100 gentagelser bliver fundet.

Det med at tage en et stort antal stikprøver af nogle observationer er også kaldet bootstrapping, hvilket forklares i [AFSNIT XXXX]


__AFSNIT SLUT__


*Magnus*
**Kan man sige ting om en population ud fra stikprøver (inferens, hvordan og hvorfor?)**

*Processen med at bruge data analyse til at sige noget om en underliggende population ud fra en stikprøve, kaldes også statistisk inferens.* Ud fra denne**(hvis?)* stikprøve vil der kunne udarbejdes statistisk analyse, som kan bruge til at drage konklusioner om populationen. Dette er meget nyttig, da det kan være nemmere at indsamle og analysere data fra en mindre mængde og så sige noget om en større mængde, end hvis man skulle indsamle mange millioner datapunkter.

I statistisk inferens differentier man normalt(?) imellem to metoder, estimering og hypotesetest.
Når der estimeres på baggrund af fra en population, bruges stikprøven til at beskrive en ukendt del af populationen. Det kan f.ek.s være gennemsnitsindkomst af danskere, hvorved der findes et estimat $\hat{\mu}$ som bruges til at beskrive $\mu$. Dette betegnes som et punkt estimat, og vil oftest suppleres med at intervalestimat. Årsagen til detter er, at punkt estimater i sin essesns er tilfældig (det ændre sig fra stikprøve til stikprøve), derfor tilstræbes det at anvende et interval, fremfor punkt estimat, da intervallet giver en større præcision i konklusionen. Her vil man finde det interval, hvor man er enten ca. 95% sikker på at $\mu$ ligger inden for.
Den anden form for statistisk inferenes, hypotesetest, bruges til at bestemme om en teori om befolkningen viser sig at være sand. En hypotesen kunne være, at danskere tjener mere i gennemsnit end folk fra Sverige. Der vil også typisk opstilles en modsat hypotese, i tilfældet af at den første hypotese, $H_0$ viser sig at være falsk. Denne modsatte hypotese vil bolt sige det modsatte og kaldes for $H_1$.

Et alternativ til statistisk inferens er bootstrapping -> Overgang?
